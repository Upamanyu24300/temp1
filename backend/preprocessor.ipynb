{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e736761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Load Excel\n",
    "df = pd.read_excel(\"data/emission_factors.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e57a4ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Section</th>\n",
       "      <th>Material</th>\n",
       "      <th>Unit of Material</th>\n",
       "      <th>Year/Timeline</th>\n",
       "      <th>Q1 Quantity</th>\n",
       "      <th>Emission Factor</th>\n",
       "      <th>Unit of Emission Factor</th>\n",
       "      <th>GHG Emission (tCO2)</th>\n",
       "      <th>Carbon Content (%)</th>\n",
       "      <th>Combustion Efficiency (%)</th>\n",
       "      <th>Data Source for Emission Factor</th>\n",
       "      <th>Location (Plant)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pellet Plant</td>\n",
       "      <td>Anthracite Coal</td>\n",
       "      <td>tonnes</td>\n",
       "      <td>Q1</td>\n",
       "      <td>136843.66</td>\n",
       "      <td>1.044</td>\n",
       "      <td>tCO2/t</td>\n",
       "      <td>1.428648e+05</td>\n",
       "      <td>88.13</td>\n",
       "      <td>89.56</td>\n",
       "      <td>IPCC 2006 Guidelines</td>\n",
       "      <td>Central Steel Plant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pellet Plant</td>\n",
       "      <td>Iron Scrap</td>\n",
       "      <td>tonnes</td>\n",
       "      <td>Q1</td>\n",
       "      <td>399043.61</td>\n",
       "      <td>2.849</td>\n",
       "      <td>tCO2/KL</td>\n",
       "      <td>1.136875e+06</td>\n",
       "      <td>91.64</td>\n",
       "      <td>90.20</td>\n",
       "      <td>IPCC 2006 Guidelines</td>\n",
       "      <td>Central Steel Plant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pellet Plant</td>\n",
       "      <td>Petroleum Coke</td>\n",
       "      <td>tonnes</td>\n",
       "      <td>Q1</td>\n",
       "      <td>92899.41</td>\n",
       "      <td>1.390</td>\n",
       "      <td>tCO2/KL</td>\n",
       "      <td>1.291302e+05</td>\n",
       "      <td>75.73</td>\n",
       "      <td>87.63</td>\n",
       "      <td>IPCC 2006 Guidelines</td>\n",
       "      <td>Central Steel Plant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pellet Plant</td>\n",
       "      <td>Bituminous Coal</td>\n",
       "      <td>tonnes</td>\n",
       "      <td>Q1</td>\n",
       "      <td>476400.55</td>\n",
       "      <td>3.084</td>\n",
       "      <td>tCO2/KL</td>\n",
       "      <td>1.469219e+06</td>\n",
       "      <td>81.49</td>\n",
       "      <td>93.63</td>\n",
       "      <td>IPCC 2006 Guidelines</td>\n",
       "      <td>Central Steel Plant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pellet Plant</td>\n",
       "      <td>Calcined Petroleum Coke</td>\n",
       "      <td>tonnes</td>\n",
       "      <td>Q1</td>\n",
       "      <td>343775.39</td>\n",
       "      <td>2.036</td>\n",
       "      <td>tCO2/t</td>\n",
       "      <td>6.999267e+05</td>\n",
       "      <td>76.71</td>\n",
       "      <td>92.55</td>\n",
       "      <td>IPCC 2006 Guidelines</td>\n",
       "      <td>Central Steel Plant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Section                 Material Unit of Material Year/Timeline  \\\n",
       "0  Pellet Plant          Anthracite Coal           tonnes            Q1   \n",
       "1  Pellet Plant               Iron Scrap           tonnes            Q1   \n",
       "2  Pellet Plant           Petroleum Coke           tonnes            Q1   \n",
       "3  Pellet Plant          Bituminous Coal           tonnes            Q1   \n",
       "4  Pellet Plant  Calcined Petroleum Coke           tonnes            Q1   \n",
       "\n",
       "   Q1 Quantity  Emission Factor Unit of Emission Factor  GHG Emission (tCO2)  \\\n",
       "0    136843.66            1.044                  tCO2/t         1.428648e+05   \n",
       "1    399043.61            2.849                 tCO2/KL         1.136875e+06   \n",
       "2     92899.41            1.390                 tCO2/KL         1.291302e+05   \n",
       "3    476400.55            3.084                 tCO2/KL         1.469219e+06   \n",
       "4    343775.39            2.036                  tCO2/t         6.999267e+05   \n",
       "\n",
       "   Carbon Content (%)  Combustion Efficiency (%)  \\\n",
       "0               88.13                      89.56   \n",
       "1               91.64                      90.20   \n",
       "2               75.73                      87.63   \n",
       "3               81.49                      93.63   \n",
       "4               76.71                      92.55   \n",
       "\n",
       "  Data Source for Emission Factor     Location (Plant)  \n",
       "0            IPCC 2006 Guidelines  Central Steel Plant  \n",
       "1            IPCC 2006 Guidelines  Central Steel Plant  \n",
       "2            IPCC 2006 Guidelines  Central Steel Plant  \n",
       "3            IPCC 2006 Guidelines  Central Steel Plant  \n",
       "4            IPCC 2006 Guidelines  Central Steel Plant  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf5c44e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and rename relevant columns\n",
    "df_factors = df[[\n",
    "    \"Material\",\n",
    "    \"Unit of Emission Factor\",\n",
    "    \"Emission Factor\",\n",
    "    \"Data Source for Emission Factor\",\n",
    "    \"Location (Plant)\",\n",
    "    \"Year/Timeline\"\n",
    "]].drop_duplicates()\n",
    "\n",
    "# Rename columns to match API expectations\n",
    "df_factors = df_factors.rename(columns={\n",
    "    \"Material\": \"material\",\n",
    "    \"Unit of Emission Factor\": \"unit\",\n",
    "    \"Emission Factor\": \"value\",\n",
    "    \"Data Source for Emission Factor\": \"source\",\n",
    "    \"Location (Plant)\": \"location\",\n",
    "    \"Year/Timeline\": \"timeline\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c421c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>material</th>\n",
       "      <th>unit</th>\n",
       "      <th>value</th>\n",
       "      <th>source</th>\n",
       "      <th>location</th>\n",
       "      <th>timeline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anthracite Coal</td>\n",
       "      <td>tCO2/t</td>\n",
       "      <td>1.044</td>\n",
       "      <td>IPCC 2006 Guidelines</td>\n",
       "      <td>Central Steel Plant</td>\n",
       "      <td>Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iron Scrap</td>\n",
       "      <td>tCO2/KL</td>\n",
       "      <td>2.849</td>\n",
       "      <td>IPCC 2006 Guidelines</td>\n",
       "      <td>Central Steel Plant</td>\n",
       "      <td>Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Petroleum Coke</td>\n",
       "      <td>tCO2/KL</td>\n",
       "      <td>1.390</td>\n",
       "      <td>IPCC 2006 Guidelines</td>\n",
       "      <td>Central Steel Plant</td>\n",
       "      <td>Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bituminous Coal</td>\n",
       "      <td>tCO2/KL</td>\n",
       "      <td>3.084</td>\n",
       "      <td>IPCC 2006 Guidelines</td>\n",
       "      <td>Central Steel Plant</td>\n",
       "      <td>Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Calcined Petroleum Coke</td>\n",
       "      <td>tCO2/t</td>\n",
       "      <td>2.036</td>\n",
       "      <td>IPCC 2006 Guidelines</td>\n",
       "      <td>Central Steel Plant</td>\n",
       "      <td>Q1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  material     unit  value                source  \\\n",
       "0          Anthracite Coal   tCO2/t  1.044  IPCC 2006 Guidelines   \n",
       "1               Iron Scrap  tCO2/KL  2.849  IPCC 2006 Guidelines   \n",
       "2           Petroleum Coke  tCO2/KL  1.390  IPCC 2006 Guidelines   \n",
       "3          Bituminous Coal  tCO2/KL  3.084  IPCC 2006 Guidelines   \n",
       "4  Calcined Petroleum Coke   tCO2/t  2.036  IPCC 2006 Guidelines   \n",
       "\n",
       "              location timeline  \n",
       "0  Central Steel Plant       Q1  \n",
       "1  Central Steel Plant       Q1  \n",
       "2  Central Steel Plant       Q1  \n",
       "3  Central Steel Plant       Q1  \n",
       "4  Central Steel Plant       Q1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_factors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28379d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add versioning logic based on timeline\n",
    "def infer_dates(timeline: str) -> tuple:\n",
    "    year = 2024  # You can parameterize this\n",
    "    if timeline == \"Q1\":\n",
    "        return f\"{year}-01-01\", f\"{year}-03-31\"\n",
    "    elif timeline == \"Q2\":\n",
    "        return f\"{year}-04-01\", f\"{year}-06-30\"\n",
    "    elif timeline == \"Q3\":\n",
    "        return f\"{year}-07-01\", f\"{year}-09-30\"\n",
    "    elif timeline == \"Q4\":\n",
    "        return f\"{year}-10-01\", f\"{year}-12-31\"\n",
    "    else:\n",
    "        return f\"{year}-01-01\", f\"{year}-12-31\"\n",
    "\n",
    "df_factors[\"start_date\"], df_factors[\"end_date\"] = zip(*df_factors[\"timeline\"].map(infer_dates))\n",
    "\n",
    "# Drop the timeline column\n",
    "df_factors = df_factors.drop(columns=[\"timeline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "641b7fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>material</th>\n",
       "      <th>unit</th>\n",
       "      <th>value</th>\n",
       "      <th>source</th>\n",
       "      <th>location</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anthracite Coal</td>\n",
       "      <td>tCO2/t</td>\n",
       "      <td>1.044</td>\n",
       "      <td>IPCC 2006 Guidelines</td>\n",
       "      <td>Central Steel Plant</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>2024-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iron Scrap</td>\n",
       "      <td>tCO2/KL</td>\n",
       "      <td>2.849</td>\n",
       "      <td>IPCC 2006 Guidelines</td>\n",
       "      <td>Central Steel Plant</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>2024-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Petroleum Coke</td>\n",
       "      <td>tCO2/KL</td>\n",
       "      <td>1.390</td>\n",
       "      <td>IPCC 2006 Guidelines</td>\n",
       "      <td>Central Steel Plant</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>2024-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bituminous Coal</td>\n",
       "      <td>tCO2/KL</td>\n",
       "      <td>3.084</td>\n",
       "      <td>IPCC 2006 Guidelines</td>\n",
       "      <td>Central Steel Plant</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>2024-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Calcined Petroleum Coke</td>\n",
       "      <td>tCO2/t</td>\n",
       "      <td>2.036</td>\n",
       "      <td>IPCC 2006 Guidelines</td>\n",
       "      <td>Central Steel Plant</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>2024-03-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  material     unit  value                source  \\\n",
       "0          Anthracite Coal   tCO2/t  1.044  IPCC 2006 Guidelines   \n",
       "1               Iron Scrap  tCO2/KL  2.849  IPCC 2006 Guidelines   \n",
       "2           Petroleum Coke  tCO2/KL  1.390  IPCC 2006 Guidelines   \n",
       "3          Bituminous Coal  tCO2/KL  3.084  IPCC 2006 Guidelines   \n",
       "4  Calcined Petroleum Coke   tCO2/t  2.036  IPCC 2006 Guidelines   \n",
       "\n",
       "              location  start_date    end_date  \n",
       "0  Central Steel Plant  2024-01-01  2024-03-31  \n",
       "1  Central Steel Plant  2024-01-01  2024-03-31  \n",
       "2  Central Steel Plant  2024-01-01  2024-03-31  \n",
       "3  Central Steel Plant  2024-01-01  2024-03-31  \n",
       "4  Central Steel Plant  2024-01-01  2024-03-31  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_factors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dfd2ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Real processed emission_factors.csv created.\n"
     ]
    }
   ],
   "source": [
    "# Save to processed CSV\n",
    "df_factors.to_csv(\"processed/emission_records.csv\", index=False)\n",
    "\n",
    "print(\"✅ Real processed emission_factors.csv created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5a84021",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2023 = df_factors.copy()\n",
    "df_2023[\"start_date\"] = pd.to_datetime(\"2023-01-01\")\n",
    "df_2023[\"end_date\"] = pd.to_datetime(\"2023-12-31\")\n",
    "\n",
    "df_all = pd.concat([df_factors, df_2023], ignore_index=True)\n",
    "df_all.to_csv(\"processed/emission_factors.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d1c73c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ emission_factors.csv now includes both 2023 and 2024 data.\n"
     ]
    }
   ],
   "source": [
    "# Load existing 2024 processed data\n",
    "df_factors_2024 = pd.read_csv(\"processed/emission_factors.csv\")\n",
    "\n",
    "df_factors_2024[\"start_date\"] = pd.to_datetime(df_factors_2024[\"start_date\"], format='mixed', errors='coerce')\n",
    "df_factors_2024[\"end_date\"] = pd.to_datetime(df_factors_2024[\"end_date\"], format='mixed', errors='coerce')\n",
    "\n",
    "# Create 2023 copy by subtracting 1 year from each date\n",
    "df_factors_2023 = df_factors_2024.copy()\n",
    "df_factors_2023[\"start_date\"] = df_factors_2023[\"start_date\"] - pd.DateOffset(years=1)\n",
    "df_factors_2023[\"end_date\"] = df_factors_2023[\"end_date\"] - pd.DateOffset(years=1)\n",
    "\n",
    "# Combine 2023 + 2024\n",
    "df_all = pd.concat([df_factors_2023, df_factors_2024], ignore_index=True)\n",
    "\n",
    "# Save final merged data\n",
    "df_all.to_csv(\"processed/emission_factors.csv\", index=False)\n",
    "\n",
    "print(\"✅ emission_factors.csv now includes both 2023 and 2024 data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05e47485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Processing 2024 data...\n",
      "🔧 Processing 2023 data...\n",
      "✅ Saved 246 emission factors to processed/emission_factors.csv\n",
      "\n",
      "📊 Summary:\n",
      "Total records: 246\n",
      "Date range: 2023-01-01 00:00:00 to 2024-06-30 00:00:00\n",
      "Materials: 63\n",
      "Locations: 1\n",
      "Years covered: [np.int32(2023), np.int32(2024)]\n",
      "\n",
      "🔍 Sample data:\n",
      "                  material     unit  value                source  \\\n",
      "0          Anthracite Coal   tCO2/t  1.044  IPCC 2006 Guidelines   \n",
      "1               Iron Scrap  tCO2/KL  2.849  IPCC 2006 Guidelines   \n",
      "2           Petroleum Coke  tCO2/KL  1.390  IPCC 2006 Guidelines   \n",
      "3          Bituminous Coal  tCO2/KL  3.084  IPCC 2006 Guidelines   \n",
      "4  Calcined Petroleum Coke   tCO2/t  2.036  IPCC 2006 Guidelines   \n",
      "\n",
      "              location start_date   end_date  \n",
      "0  Central Steel Plant 2023-01-01 2023-03-31  \n",
      "1  Central Steel Plant 2023-01-01 2023-03-31  \n",
      "2  Central Steel Plant 2023-01-01 2023-03-31  \n",
      "3  Central Steel Plant 2023-01-01 2023-03-31  \n",
      "4  Central Steel Plant 2023-01-01 2023-03-31  \n",
      "\n",
      "🎉 Preprocessing complete! Your data is ready for use.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, date\n",
    "import os\n",
    "\n",
    "# Ensure the processed directory exists\n",
    "os.makedirs(\"processed\", exist_ok=True)\n",
    "\n",
    "# Load Excel\n",
    "df = pd.read_excel(\"data/emission_factors.xlsx\")\n",
    "\n",
    "# Filter and rename relevant columns\n",
    "df_factors = df[[\n",
    "    \"Material\",\n",
    "    \"Unit of Emission Factor\",\n",
    "    \"Emission Factor\",\n",
    "    \"Data Source for Emission Factor\",\n",
    "    \"Location (Plant)\",\n",
    "    \"Year/Timeline\"\n",
    "]].drop_duplicates()\n",
    "\n",
    "# Rename columns to match API expectations\n",
    "df_factors = df_factors.rename(columns={\n",
    "    \"Material\": \"material\",\n",
    "    \"Unit of Emission Factor\": \"unit\",\n",
    "    \"Emission Factor\": \"value\",\n",
    "    \"Data Source for Emission Factor\": \"source\",\n",
    "    \"Location (Plant)\": \"location\",\n",
    "    \"Year/Timeline\": \"timeline\"\n",
    "})\n",
    "\n",
    "# Add versioning logic based on timeline\n",
    "def infer_dates(timeline: str, year: int = 2024) -> tuple:\n",
    "    \"\"\"Infer start and end dates from timeline string\"\"\"\n",
    "    timeline_str = str(timeline).strip().upper()\n",
    "    \n",
    "    if timeline_str == \"Q1\":\n",
    "        return f\"{year}-01-01\", f\"{year}-03-31\"\n",
    "    elif timeline_str == \"Q2\":\n",
    "        return f\"{year}-04-01\", f\"{year}-06-30\"\n",
    "    elif timeline_str == \"Q3\":\n",
    "        return f\"{year}-07-01\", f\"{year}-09-30\"\n",
    "    elif timeline_str == \"Q4\":\n",
    "        return f\"{year}-10-01\", f\"{year}-12-31\"\n",
    "    else:\n",
    "        # Default to full year\n",
    "        return f\"{year}-01-01\", f\"{year}-12-31\"\n",
    "\n",
    "# Process 2024 data\n",
    "print(\"🔧 Processing 2024 data...\")\n",
    "df_2024 = df_factors.copy()\n",
    "df_2024[[\"start_date\", \"end_date\"]] = df_2024[\"timeline\"].apply(\n",
    "    lambda x: pd.Series(infer_dates(x, 2024))\n",
    ")\n",
    "\n",
    "# Process 2023 data\n",
    "print(\"🔧 Processing 2023 data...\")\n",
    "df_2023 = df_factors.copy()\n",
    "df_2023[[\"start_date\", \"end_date\"]] = df_2023[\"timeline\"].apply(\n",
    "    lambda x: pd.Series(infer_dates(x, 2023))\n",
    ")\n",
    "\n",
    "# Combine 2023 and 2024 data\n",
    "df_all = pd.concat([df_2023, df_2024], ignore_index=True)\n",
    "\n",
    "# Drop the timeline column as it's no longer needed\n",
    "df_all = df_all.drop(columns=[\"timeline\"])\n",
    "\n",
    "# Convert date columns to proper datetime format\n",
    "df_all[\"start_date\"] = pd.to_datetime(df_all[\"start_date\"])\n",
    "df_all[\"end_date\"] = pd.to_datetime(df_all[\"end_date\"])\n",
    "\n",
    "# Save to processed CSV\n",
    "output_path = \"processed/emission_factors.csv\"\n",
    "df_all.to_csv(output_path, index=False)\n",
    "print(f\"✅ Saved {len(df_all)} emission factors to {output_path}\")\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n📊 Summary:\")\n",
    "print(f\"Total records: {len(df_all)}\")\n",
    "print(f\"Date range: {df_all['start_date'].min()} to {df_all['end_date'].max()}\")\n",
    "print(f\"Materials: {df_all['material'].nunique()}\")\n",
    "print(f\"Locations: {df_all['location'].nunique()}\")\n",
    "print(f\"Years covered: {sorted(df_all['start_date'].dt.year.unique())}\")\n",
    "\n",
    "# Show a sample of the data\n",
    "print(\"\\n🔍 Sample data:\")\n",
    "print(df_all.head())\n",
    "\n",
    "# Create sample business metrics if it doesn't exist\n",
    "business_metrics_path = \"processed/business_metrics.csv\"\n",
    "if not os.path.exists(business_metrics_path):\n",
    "    print(f\"\\n🔧 Creating sample business metrics...\")\n",
    "    \n",
    "    # Generate sample business metrics for 2023 and 2024\n",
    "    dates_2023 = pd.date_range(start=\"2023-01-01\", end=\"2023-12-31\", freq=\"M\")\n",
    "    dates_2024 = pd.date_range(start=\"2024-01-01\", end=\"2024-12-31\", freq=\"M\")\n",
    "    \n",
    "    business_metrics = []\n",
    "    \n",
    "    # Add sample data for both years\n",
    "    for date_val in list(dates_2023) + list(dates_2024):\n",
    "        business_metrics.extend([\n",
    "            {\n",
    "                \"date\": date_val.strftime(\"%Y-%m-%d\"),\n",
    "                \"metric_name\": \"Tons of Steel Produced\",\n",
    "                \"value\": 50000 + (date_val.month * 1000)  # Varying production\n",
    "            },\n",
    "            {\n",
    "                \"date\": date_val.strftime(\"%Y-%m-%d\"),\n",
    "                \"metric_name\": \"Number of Employees\",\n",
    "                \"value\": 1000 + (date_val.month * 10)  # Varying workforce\n",
    "            }\n",
    "        ])\n",
    "    \n",
    "    df_metrics = pd.DataFrame(business_metrics)\n",
    "    df_metrics.to_csv(business_metrics_path, index=False)\n",
    "    print(f\"✅ Created sample business metrics: {len(df_metrics)} records\")\n",
    "\n",
    "print(\"\\n🎉 Preprocessing complete! Your data is ready for use.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "401e4168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Creating business metrics for Carbon Emissions Platform...\n",
      "============================================================\n",
      "✅ Created business metrics file: processed/business_metrics.csv\n",
      "📊 Total records: 72\n",
      "📊 Metrics: ['Tons of Steel Produced' 'Number of Employees' 'Production Hours']\n",
      "📊 Date range: 2023-01-01 to 2024-12-01\n",
      "\n",
      "🔍 Sample data:\n",
      "         date             metric_name  value\n",
      "0  2023-01-01  Tons of Steel Produced  47000\n",
      "1  2023-01-01     Number of Employees    958\n",
      "2  2023-01-01        Production Hours   7300\n",
      "3  2023-02-01  Tons of Steel Produced  49000\n",
      "4  2023-02-01     Number of Employees    966\n",
      "5  2023-02-01        Production Hours   7400\n",
      "6  2023-03-01  Tons of Steel Produced  49500\n",
      "7  2023-03-01     Number of Employees    974\n",
      "8  2023-03-01        Production Hours   7500\n",
      "9  2023-04-01  Tons of Steel Produced  51500\n",
      "\n",
      "============================================================\n",
      "🔍 Verifying all files...\n",
      "🔍 Verifying required files...\n",
      "✅ processed/emission_factors.csv - 246 records\n",
      "✅ processed/business_metrics.csv - 72 records\n",
      "✅ processed/emission_records.csv - 128 records\n",
      "\n",
      "============================================================\n",
      "✅ Setup complete!\n",
      "\n",
      "📋 Now you can test the intensity endpoint:\n",
      "   GET http://127.0.0.1:8000/analytics/intensity\n",
      "\n",
      "💡 Note: You need to have some emission records first.\n",
      "   Add records using: POST http://127.0.0.1:8000/emission-records\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def create_business_metrics():\n",
    "    \"\"\"Create business metrics file with sample data\"\"\"\n",
    "    \n",
    "    # Ensure processed directory exists\n",
    "    os.makedirs(\"processed\", exist_ok=True)\n",
    "    \n",
    "    # Create date range for both 2023 and 2024\n",
    "    start_date_2023 = datetime(2023, 1, 1)\n",
    "    end_date_2023 = datetime(2023, 12, 31)\n",
    "    start_date_2024 = datetime(2024, 1, 1)\n",
    "    end_date_2024 = datetime(2024, 12, 31)\n",
    "    \n",
    "    # Generate monthly data points\n",
    "    business_metrics = []\n",
    "    \n",
    "    # Generate data for 2023\n",
    "    current_date = start_date_2023\n",
    "    while current_date <= end_date_2023:\n",
    "        # Add monthly data for different metrics\n",
    "        business_metrics.extend([\n",
    "            {\n",
    "                \"date\": current_date.strftime(\"%Y-%m-%d\"),\n",
    "                \"metric_name\": \"Tons of Steel Produced\",\n",
    "                \"value\": 45000 + (current_date.month * 1500) + (current_date.month % 3 * 500)  # Monthly variation\n",
    "            },\n",
    "            {\n",
    "                \"date\": current_date.strftime(\"%Y-%m-%d\"),\n",
    "                \"metric_name\": \"Number of Employees\",\n",
    "                \"value\": 950 + (current_date.month * 8)\n",
    "            },\n",
    "            {\n",
    "                \"date\": current_date.strftime(\"%Y-%m-%d\"),\n",
    "                \"metric_name\": \"Production Hours\",\n",
    "                \"value\": 7200 + (current_date.month * 100)\n",
    "            }\n",
    "        ])\n",
    "        \n",
    "        # Move to next month\n",
    "        if current_date.month == 12:\n",
    "            current_date = current_date.replace(year=current_date.year + 1, month=1)\n",
    "        else:\n",
    "            current_date = current_date.replace(month=current_date.month + 1)\n",
    "    \n",
    "    # Generate data for 2024\n",
    "    current_date = start_date_2024\n",
    "    while current_date <= end_date_2024:\n",
    "        # Add monthly data for different metrics with slight increase from 2023\n",
    "        business_metrics.extend([\n",
    "            {\n",
    "                \"date\": current_date.strftime(\"%Y-%m-%d\"),\n",
    "                \"metric_name\": \"Tons of Steel Produced\",\n",
    "                \"value\": 47000 + (current_date.month * 1600) + (current_date.month % 3 * 600)  # 2024 growth\n",
    "            },\n",
    "            {\n",
    "                \"date\": current_date.strftime(\"%Y-%m-%d\"),\n",
    "                \"metric_name\": \"Number of Employees\",\n",
    "                \"value\": 980 + (current_date.month * 9)\n",
    "            },\n",
    "            {\n",
    "                \"date\": current_date.strftime(\"%Y-%m-%d\"),\n",
    "                \"metric_name\": \"Production Hours\",\n",
    "                \"value\": 7400 + (current_date.month * 110)\n",
    "            }\n",
    "        ])\n",
    "        \n",
    "        # Move to next month\n",
    "        if current_date.month == 12:\n",
    "            current_date = current_date.replace(year=current_date.year + 1, month=1)\n",
    "        else:\n",
    "            current_date = current_date.replace(month=current_date.month + 1)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_metrics = pd.DataFrame(business_metrics)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_path = \"processed/business_metrics.csv\"\n",
    "    df_metrics.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"✅ Created business metrics file: {output_path}\")\n",
    "    print(f\"📊 Total records: {len(df_metrics)}\")\n",
    "    print(f\"📊 Metrics: {df_metrics['metric_name'].unique()}\")\n",
    "    print(f\"📊 Date range: {df_metrics['date'].min()} to {df_metrics['date'].max()}\")\n",
    "    \n",
    "    # Show sample data\n",
    "    print(\"\\n🔍 Sample data:\")\n",
    "    print(df_metrics.head(10))\n",
    "    \n",
    "    return df_metrics\n",
    "\n",
    "def verify_files():\n",
    "    \"\"\"Verify that all required files exist\"\"\"\n",
    "    \n",
    "    required_files = [\n",
    "        \"processed/emission_factors.csv\",\n",
    "        \"processed/business_metrics.csv\"\n",
    "    ]\n",
    "    \n",
    "    print(\"🔍 Verifying required files...\")\n",
    "    \n",
    "    for file_path in required_files:\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path)\n",
    "            print(f\"✅ {file_path} - {len(df)} records\")\n",
    "        else:\n",
    "            print(f\"❌ {file_path} - Missing!\")\n",
    "    \n",
    "    # Check if emission_records.csv exists (created when you add records)\n",
    "    records_path = \"processed/emission_records.csv\"\n",
    "    if os.path.exists(records_path):\n",
    "        df_records = pd.read_csv(records_path)\n",
    "        print(f\"✅ {records_path} - {len(df_records)} records\")\n",
    "    else:\n",
    "        print(f\"⚠️  {records_path} - Will be created when you add emission records\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚀 Creating business metrics for Carbon Emissions Platform...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create business metrics\n",
    "    df_metrics = create_business_metrics()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"🔍 Verifying all files...\")\n",
    "    \n",
    "    # Verify files\n",
    "    verify_files()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"✅ Setup complete!\")\n",
    "    print(\"\\n📋 Now you can test the intensity endpoint:\")\n",
    "    print(\"   GET http://127.0.0.1:8000/analytics/intensity\")\n",
    "    print(\"\\n💡 Note: You need to have some emission records first.\")\n",
    "    print(\"   Add records using: POST http://127.0.0.1:8000/emission-records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41f62ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Debugging Intensity Endpoint...\n",
      "============================================================\n",
      "\n",
      "🔍 Analyzing Data Alignment...\n",
      "==================================================\n",
      "📊 Emission Records: 128 records\n",
      "   📅 Emission periods: ['NaT', '2023-06', '2024-06']\n",
      "📊 Business Metrics: 72 records\n",
      "   📅 Metric periods: ['2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06', '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12', '2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06', '2024-07', '2024-08', '2024-09', '2024-10', '2024-11', '2024-12']\n",
      "   📋 Available metrics: ['Tons of Steel Produced' 'Number of Employees' 'Production Hours']\n",
      "   🏭 Steel production periods: ['2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06', '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12', '2024-01', '2024-02', '2024-03', '2024-04', '2024-05', '2024-06', '2024-07', '2024-08', '2024-09', '2024-10', '2024-11', '2024-12']\n",
      "\n",
      "============================================================\n",
      "🧪 Testing Intensity Endpoint...\n",
      "==================================================\n",
      "1️⃣ Checking required files...\n",
      "   ✅ processed/emission_factors.csv - 246 records\n",
      "      📊 Columns: ['material', 'unit', 'value', 'source', 'location', 'start_date', 'end_date']\n",
      "   ✅ processed/business_metrics.csv - 72 records\n",
      "      📊 Columns: ['date', 'metric_name', 'value']\n",
      "      📅 Date range: 2023-01-01 to 2024-12-01\n",
      "   ✅ processed/emission_records.csv - 128 records\n",
      "      📊 Columns: ['material', 'unit', 'value', 'source', 'location', 'start_date', 'end_date', 'quantity', 'date_of_activity', 'emission_kg_co2e']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 173\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# Then test the endpoint\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[43mtest_intensity_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Debugging complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 35\u001b[0m, in \u001b[0;36mtest_intensity_endpoint\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m      📅 Date range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate_of_activity\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m---> 35\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m      📅 Date range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate_of_activity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_of_activity\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   ❌ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Missing!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\ml_proj_shri\\temp\\backend\\env\\lib\\site-packages\\pandas\\core\\series.py:6518\u001b[0m, in \u001b[0;36mSeries.min\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m   6510\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   6511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmin\u001b[39m(\n\u001b[0;32m   6512\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6516\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   6517\u001b[0m ):\n\u001b[1;32m-> 6518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmin(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\ml_proj_shri\\temp\\backend\\env\\lib\\site-packages\\pandas\\core\\generic.py:12407\u001b[0m, in \u001b[0;36mNDFrame.min\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmin\u001b[39m(\n\u001b[0;32m  12401\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  12402\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12405\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  12406\u001b[0m ):\n\u001b[1;32m> 12407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  12408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m  12409\u001b[0m         nanops\u001b[38;5;241m.\u001b[39mnanmin,\n\u001b[0;32m  12410\u001b[0m         axis,\n\u001b[0;32m  12411\u001b[0m         skipna,\n\u001b[0;32m  12412\u001b[0m         numeric_only,\n\u001b[0;32m  12413\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  12414\u001b[0m     )\n",
      "File \u001b[1;32md:\\ml_proj_shri\\temp\\backend\\env\\lib\\site-packages\\pandas\\core\\generic.py:12396\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12392\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[0;32m  12394\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 12396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  12397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[0;32m  12398\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ml_proj_shri\\temp\\backend\\env\\lib\\site-packages\\pandas\\core\\series.py:6468\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   6463\u001b[0m     \u001b[38;5;66;03m# GH#47500 - change to TypeError to match other methods\u001b[39;00m\n\u001b[0;32m   6464\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   6465\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6466\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6467\u001b[0m     )\n\u001b[1;32m-> 6468\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32md:\\ml_proj_shri\\temp\\backend\\env\\lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    145\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\ml_proj_shri\\temp\\backend\\env\\lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[0;32m    407\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[1;32md:\\ml_proj_shri\\temp\\backend\\env\\lib\\site-packages\\pandas\\core\\nanops.py:1098\u001b[0m, in \u001b[0;36m_nanminmax.<locals>.reduction\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _na_for_min_count(values, axis)\n\u001b[0;32m   1095\u001b[0m values, mask \u001b[38;5;241m=\u001b[39m _get_values(\n\u001b[0;32m   1096\u001b[0m     values, skipna, fill_value_typ\u001b[38;5;241m=\u001b[39mfill_value_typ, mask\u001b[38;5;241m=\u001b[39mmask\n\u001b[0;32m   1097\u001b[0m )\n\u001b[1;32m-> 1098\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m result \u001b[38;5;241m=\u001b[39m _maybe_null_out(result, axis, mask, values\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\ml_proj_shri\\temp\\backend\\env\\lib\\site-packages\\numpy\\_core\\_methods.py:48\u001b[0m, in \u001b[0;36m_amin\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_amin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     47\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_minimum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<=' not supported between instances of 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, date\n",
    "\n",
    "def test_intensity_endpoint():\n",
    "    \"\"\"Test the intensity endpoint step by step\"\"\"\n",
    "    \n",
    "    base_url = \"http://127.0.0.1:8000\"\n",
    "    \n",
    "    print(\"🧪 Testing Intensity Endpoint...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Step 1: Check if files exist\n",
    "    print(\"1️⃣ Checking required files...\")\n",
    "    \n",
    "    required_files = [\n",
    "        \"processed/emission_factors.csv\",\n",
    "        \"processed/business_metrics.csv\",\n",
    "        \"processed/emission_records.csv\"\n",
    "    ]\n",
    "    \n",
    "    for file_path in required_files:\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path)\n",
    "            print(f\"   ✅ {file_path} - {len(df)} records\")\n",
    "            \n",
    "            # Show sample data\n",
    "            if len(df) > 0:\n",
    "                print(f\"      📊 Columns: {list(df.columns)}\")\n",
    "                if \"date\" in df.columns:\n",
    "                    print(f\"      📅 Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "                elif \"date_of_activity\" in df.columns:\n",
    "                    print(f\"      📅 Date range: {df['date_of_activity'].min()} to {df['date_of_activity'].max()}\")\n",
    "        else:\n",
    "            print(f\"   ❌ {file_path} - Missing!\")\n",
    "    \n",
    "    # Step 2: Add some emission records if none exist\n",
    "    print(\"\\n2️⃣ Ensuring emission records exist...\")\n",
    "    \n",
    "    if not os.path.exists(\"processed/emission_records.csv\") or len(pd.read_csv(\"processed/emission_records.csv\")) == 0:\n",
    "        print(\"   📝 Adding sample emission records...\")\n",
    "        \n",
    "        sample_records = [\n",
    "            {\n",
    "                \"material\": \"Petroleum Coke\",\n",
    "                \"quantity\": 100,\n",
    "                \"unit\": \"tCO2/KL\",\n",
    "                \"date_of_activity\": \"2023-01-15\",\n",
    "                \"location\": \"Central Steel Plant\"\n",
    "            },\n",
    "            {\n",
    "                \"material\": \"Petroleum Coke\",\n",
    "                \"quantity\": 150,\n",
    "                \"unit\": \"tCO2/KL\",\n",
    "                \"date_of_activity\": \"2023-02-15\",\n",
    "                \"location\": \"Central Steel Plant\"\n",
    "            },\n",
    "            {\n",
    "                \"material\": \"Natural Gas\",\n",
    "                \"quantity\": 200,\n",
    "                \"unit\": \"tCO2/m3\",\n",
    "                \"date_of_activity\": \"2023-03-15\",\n",
    "                \"location\": \"Central Steel Plant\"\n",
    "            },\n",
    "            {\n",
    "                \"material\": \"Petroleum Coke\",\n",
    "                \"quantity\": 120,\n",
    "                \"unit\": \"tCO2/KL\",\n",
    "                \"date_of_activity\": \"2024-01-15\",\n",
    "                \"location\": \"Central Steel Plant\"\n",
    "            },\n",
    "            {\n",
    "                \"material\": \"Petroleum Coke\",\n",
    "                \"quantity\": 180,\n",
    "                \"unit\": \"tCO2/KL\",\n",
    "                \"date_of_activity\": \"2024-02-15\",\n",
    "                \"location\": \"Central Steel Plant\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        for record in sample_records:\n",
    "            try:\n",
    "                response = requests.post(f\"{base_url}/emission-records\", json=record)\n",
    "                if response.status_code == 200:\n",
    "                    print(f\"   ✅ Added record for {record['date_of_activity']}\")\n",
    "                else:\n",
    "                    print(f\"   ❌ Failed to add record: {response.status_code} - {response.text}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ Error adding record: {e}\")\n",
    "    \n",
    "    # Step 3: Test the intensity endpoint\n",
    "    print(\"\\n3️⃣ Testing intensity endpoint...\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(f\"{base_url}/analytics/intensity\")\n",
    "        print(f\"   📡 Response status: {response.status_code}\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(f\"   ✅ Success! Result:\")\n",
    "            print(f\"      {json.dumps(result, indent=2)}\")\n",
    "        else:\n",
    "            print(f\"   ❌ Error response:\")\n",
    "            print(f\"      {response.text}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Request failed: {e}\")\n",
    "    \n",
    "    # Step 4: Debug the function directly\n",
    "    print(\"\\n4️⃣ Testing function directly...\")\n",
    "    \n",
    "    try:\n",
    "        # Import and test the function directly\n",
    "        from emissions_logic import get_emission_intensity\n",
    "        \n",
    "        result = get_emission_intensity()\n",
    "        print(f\"   ✅ Direct function call successful:\")\n",
    "        print(f\"      {json.dumps(result, indent=2)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Direct function call failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "def analyze_data_alignment():\n",
    "    \"\"\"Analyze if emission records and business metrics align properly\"\"\"\n",
    "    \n",
    "    print(\"\\n🔍 Analyzing Data Alignment...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check emission records\n",
    "    if os.path.exists(\"processed/emission_records.csv\"):\n",
    "        df_emissions = pd.read_csv(\"processed/emission_records.csv\", parse_dates=[\"date_of_activity\"])\n",
    "        print(f\"📊 Emission Records: {len(df_emissions)} records\")\n",
    "        \n",
    "        if len(df_emissions) > 0:\n",
    "            df_emissions[\"year_month\"] = df_emissions[\"date_of_activity\"].dt.to_period(\"M\")\n",
    "            emission_periods = df_emissions[\"year_month\"].unique()\n",
    "            print(f\"   📅 Emission periods: {[str(p) for p in sorted(emission_periods)]}\")\n",
    "    \n",
    "    # Check business metrics\n",
    "    if os.path.exists(\"processed/business_metrics.csv\"):\n",
    "        df_metrics = pd.read_csv(\"processed/business_metrics.csv\", parse_dates=[\"date\"])\n",
    "        print(f\"📊 Business Metrics: {len(df_metrics)} records\")\n",
    "        \n",
    "        if len(df_metrics) > 0:\n",
    "            df_metrics[\"year_month\"] = df_metrics[\"date\"].dt.to_period(\"M\")\n",
    "            metric_periods = df_metrics[\"year_month\"].unique()\n",
    "            print(f\"   📅 Metric periods: {[str(p) for p in sorted(metric_periods)]}\")\n",
    "            \n",
    "            # Show available metrics\n",
    "            metrics = df_metrics[\"metric_name\"].unique()\n",
    "            print(f\"   📋 Available metrics: {metrics}\")\n",
    "            \n",
    "            # Check for \"Tons of Steel Produced\"\n",
    "            steel_metrics = df_metrics[df_metrics[\"metric_name\"] == \"Tons of Steel Produced\"]\n",
    "            if len(steel_metrics) > 0:\n",
    "                steel_periods = steel_metrics[\"year_month\"].unique()\n",
    "                print(f\"   🏭 Steel production periods: {[str(p) for p in sorted(steel_periods)]}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚀 Debugging Intensity Endpoint...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # First analyze data alignment\n",
    "    analyze_data_alignment()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    \n",
    "    # Then test the endpoint\n",
    "    test_intensity_endpoint()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"✅ Debugging complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73386081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
